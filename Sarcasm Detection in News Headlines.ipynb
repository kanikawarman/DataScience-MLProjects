{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd702e94",
   "metadata": {},
   "source": [
    "# **Sarcasm Detection in News Headlines**\n",
    "\n",
    "**Objective:**\n",
    "\n",
    "To use Logistic Regression to predict whether a news headline is sarcastic or not, based on linguistic features and sentiment analysis.\n",
    "\n",
    "## Introduction\n",
    "In this project, we aim to detect sarcasm in news headlines using logistic regression. Sarcasm is a nuanced form of communication that can often be difficult for machines to understand. By leveraging linguistic features such as sentiment analysis and other text-based characteristics, we will train a machine learning model to differentiate between sarcastic and non-sarcastic headlines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7950501",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "The training data consists of news headlines and a label indicating whether each headline is sarcastic (`1`) or not (`0`). We will load both the training and test datasets and the required libraries for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#Text preprocessing\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import contractions\n",
    "import tqdm\n",
    "import textsearch\n",
    "import string\n",
    "import textblob\n",
    "\n",
    "#Model training\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f59b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and Loading Dataset\n",
    "df_train = pd.read_csv('assign_data/Train_Data.csv')\n",
    "df_test = pd.read_csv('assign_data/Test_Data.csv')\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c54e0",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "We will first explore the dataset to check for missing values, data types, and general statistics. \n",
    "The output shows no null values in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f772a92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 44262 entries, 0 to 44261\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   headline      44262 non-null  object\n",
      " 1   is_sarcastic  44262 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 691.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking missing data\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "515009ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>area stand-up comedian questions the deal with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dozens of glowing exit signs mercilessly taunt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perfect response to heckler somewhere in prop ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gop prays for ossoff lossoff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trevor noah says the scary truth about trump's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline\n",
       "0  area stand-up comedian questions the deal with...\n",
       "1  dozens of glowing exit signs mercilessly taunt...\n",
       "2  perfect response to heckler somewhere in prop ...\n",
       "3                       gop prays for ossoff lossoff\n",
       "4  trevor noah says the scary truth about trump's..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227ab8a",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "We begin by selecting the relevant features from the dataset. The headline text is used as the primary feature for both training and testing, and the target variable is the 'is_sarcastic' column from the training dataset. \n",
    "\n",
    "In the code below:\n",
    "\n",
    "- X_train contains the headlines from the training dataset.\n",
    "- Y_train represents the labels indicating whether each headline is sarcastic (1) or not (0).\n",
    "- X_test consists of the headlines from the test dataset, which will be used for making predictions.\n",
    "\n",
    "This step isolates the textual data from the rest of the dataset so it can later be processed for further feature extraction and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5bf0746",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train=df_train[['headline']], df_train[['is_sarcastic']]\n",
    "X_test=df_test[['headline']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b5e241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline\n",
       "0  supreme court votes 7-2 to legalize all worldl...\n",
       "1  hungover man horrified to learn he made dozens...\n",
       "2  emily's list founder: women are the 'problem s...\n",
       "3      send your kids back to school with confidence\n",
       "4          watch: experts talk pesticides and health"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cc2106",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "Before feeding the text data into our logistic regression model, we need to transform the raw headlines into features that capture meaningful linguistic patterns. This step involves creating numerical representations of various text properties that may be indicative of sarcasm. We do this by applying several preprocessing steps to both the training and testing datasets. we will preprocess the headlines by expanding contractions, removing punctuation, and applying stemming and stopwords removal. We will create various text-based features from the headlines, such as character count, word count, punctuation, and sentiment scores (polarity and subjectivity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c36ffc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre- Processing train and test data\n",
    "X_train['char_count'] = X_train['headline'].apply(len)\n",
    "X_train['word_count'] = X_train['headline'].apply(lambda x: len(x.split()))\n",
    "X_train['word_density'] = X_train['char_count'] / (X_train['word_count']+1)\n",
    "X_train['punctuation_count'] = X_train['headline'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_train['title_word_count'] = X_train['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_train['upper_case_word_count'] = X_train['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "X_test['char_count'] = X_test['headline'].apply(len)\n",
    "X_test['word_count'] = X_test['headline'].apply(lambda x: len(x.split()))\n",
    "X_test['word_density'] = X_test['char_count'] / (X_train['word_count']+1)\n",
    "X_test['punctuation_count'] = X_test['headline'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_test['title_word_count'] = X_test['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_test['upper_case_word_count'] = X_test['headline'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25cb1d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  char_count  word_count  \\\n",
       "0  supreme court votes 7-2 to legalize all worldl...          53           9   \n",
       "1  hungover man horrified to learn he made dozens...          66          12   \n",
       "2  emily's list founder: women are the 'problem s...          65          10   \n",
       "3      send your kids back to school with confidence          45           8   \n",
       "4          watch: experts talk pesticides and health          41           6   \n",
       "\n",
       "   word_density  punctuation_count  title_word_count  upper_case_word_count  \n",
       "0      5.300000                  1                 0                      0  \n",
       "1      5.076923                  0                 0                      0  \n",
       "2      5.909091                  4                 0                      0  \n",
       "3      5.000000                  0                 0                      0  \n",
       "4      5.857143                  1                 0                      0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "930ab056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>area stand-up comedian questions the deal with...</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dozens of glowing exit signs mercilessly taunt...</td>\n",
       "      <td>65</td>\n",
       "      <td>9</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perfect response to heckler somewhere in prop ...</td>\n",
       "      <td>62</td>\n",
       "      <td>9</td>\n",
       "      <td>5.636364</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gop prays for ossoff lossoff</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trevor noah says the scary truth about trump's...</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  char_count  word_count  \\\n",
       "0  area stand-up comedian questions the deal with...          65           9   \n",
       "1  dozens of glowing exit signs mercilessly taunt...          65           9   \n",
       "2  perfect response to heckler somewhere in prop ...          62           9   \n",
       "3                       gop prays for ossoff lossoff          28           5   \n",
       "4  trevor noah says the scary truth about trump's...          65          11   \n",
       "\n",
       "   word_density  punctuation_count  title_word_count  upper_case_word_count  \n",
       "0      6.500000                  2                 0                      0  \n",
       "1      5.000000                  0                 0                      0  \n",
       "2      5.636364                  1                 0                      0  \n",
       "3      3.111111                  0                 0                      0  \n",
       "4      9.285714                  1                 0                      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c126b2",
   "metadata": {},
   "source": [
    "We have extracted the following features:\n",
    "\n",
    "- Character Count: Measures the total number of characters in a headline. Longer headlines may contain more clues about sarcasm.\n",
    "- Word Count: Represents the total number of words in a headline, which helps in identifying complex or short phrases.\n",
    "- Word Density: Calculated as the ratio of character count to word count, this feature captures the average length of words in a headline.\n",
    "- Punctuation Count: Measures the number of punctuation marks. Sarcastic headlines might include more punctuation to emphasize tone.\n",
    "- Title Word Count: Tracks how many words in the headline are title-cased (i.e., capitalized). Headlines with more title-case words may indicate formality or emphasis.\n",
    "- Uppercase Word Count: Counts the number of fully uppercase words, which might suggest a sarcastic or exaggerated tone.\n",
    "- These features will help our model understand various linguistic patterns that could be correlated with sarcasm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036c5575",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "In this section, we will focus on building features from the sentiment analysis of headlines and preprocessing the text data for use in machine learning.\n",
    "\n",
    "1. **Features from Sentiment Analysis:**\n",
    "We utilize TextBlob to extract sentiment-based features, which are Polarity and Subjectivity, for each headline:\n",
    "\n",
    "- Polarity: A score between -1 (negative sentiment) and 1 (positive sentiment).\n",
    "- Subjectivity: A score between 0 (objective) and 1 (subjective).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d135d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from Sentiment analysis\n",
    "x_train_snt_obj = X_train['headline'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_train['Polarity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
    "X_train['Subjectivity'] = [obj.subjectivity for obj in x_train_snt_obj.values]\n",
    "\n",
    "x_test_snt_obj = X_test['headline'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_test['Polarity'] = [obj.polarity for obj in x_test_snt_obj.values]\n",
    "X_test['Subjectivity'] = [obj.subjectivity for obj in x_test_snt_obj.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ca3f7",
   "metadata": {},
   "source": [
    "**Output:** This creates two new columns in the dataset:\n",
    "\n",
    "- Polarity: The sentiment polarity score.\n",
    "- Subjectivity: The sentiment subjectivity score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b1d4bfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  char_count  word_count  \\\n",
       "0  supreme court votes 7-2 to legalize all worldl...          53           9   \n",
       "1  hungover man horrified to learn he made dozens...          66          12   \n",
       "2  emily's list founder: women are the 'problem s...          65          10   \n",
       "3      send your kids back to school with confidence          45           8   \n",
       "4          watch: experts talk pesticides and health          41           6   \n",
       "\n",
       "   word_density  punctuation_count  title_word_count  upper_case_word_count  \\\n",
       "0      5.300000                  1                 0                      0   \n",
       "1      5.076923                  0                 0                      0   \n",
       "2      5.909091                  4                 0                      0   \n",
       "3      5.000000                  0                 0                      0   \n",
       "4      5.857143                  1                 0                      0   \n",
       "\n",
       "   Polarity  Subjectivity  \n",
       "0       0.0      0.000000  \n",
       "1       0.0      0.066667  \n",
       "2       0.0      0.000000  \n",
       "3       0.0      0.000000  \n",
       "4       0.0      0.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe263e1",
   "metadata": {},
   "source": [
    "2. **Text Preprocessing and Feature Engineering:**\n",
    "\n",
    "We use the Natural Language Toolkit (nltk) for tokenizing and removing stopwords, followed by a Porter Stemmer to stem the words. Some common stopwords such as 'no,' 'not,' and 'but' are preserved to capture negation in sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12e16a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Think\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Think\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#Text Pre-processing wna rangiling\n",
    "# remove some stopwords to capture negation in n-grams if possible\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('but')\n",
    "\n",
    "# load up a simple porter stemmer - nothing fancy\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "def simple_text_preprocessor(document): \n",
    "    # lower case\n",
    "    document = str(document).lower()\n",
    "    \n",
    "    # expand contractions\n",
    "    document = contractions.fix(document)\n",
    "    \n",
    "    # remove unnecessary characters\n",
    "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
    "    document = re.sub(r'nbsp', r'', document)\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    \n",
    "    # simple porter stemming\n",
    "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
    "    \n",
    "    # stopwords removal\n",
    "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
    "    \n",
    "    return document\n",
    "\n",
    "stp = np.vectorize(simple_text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "783b032a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Clean Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>suprem court vote legal worldli vice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>hungov man horrifi learn made dozen plan last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>emili list founder women problem solver congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>send kid back school confid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>watch expert talk pesticid health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  char_count  word_count  \\\n",
       "0  supreme court votes 7-2 to legalize all worldl...          53           9   \n",
       "1  hungover man horrified to learn he made dozens...          66          12   \n",
       "2  emily's list founder: women are the 'problem s...          65          10   \n",
       "3      send your kids back to school with confidence          45           8   \n",
       "4          watch: experts talk pesticides and health          41           6   \n",
       "\n",
       "   word_density  punctuation_count  title_word_count  upper_case_word_count  \\\n",
       "0      5.300000                  1                 0                      0   \n",
       "1      5.076923                  0                 0                      0   \n",
       "2      5.909091                  4                 0                      0   \n",
       "3      5.000000                  0                 0                      0   \n",
       "4      5.857143                  1                 0                      0   \n",
       "\n",
       "   Polarity  Subjectivity                                     Clean Headline  \n",
       "0       0.0      0.000000               suprem court vote legal worldli vice  \n",
       "1       0.0      0.066667  hungov man horrifi learn made dozen plan last ...  \n",
       "2       0.0      0.000000   emili list founder women problem solver congress  \n",
       "3       0.0      0.000000                        send kid back school confid  \n",
       "4       0.0      0.000000                  watch expert talk pesticid health  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Clean Headline'] = stp(X_train['headline'].values)\n",
    "X_test['Clean Headline'] = stp(X_test['headline'].values)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51648986",
   "metadata": {},
   "source": [
    "**Output:** The Clean Headline column is added, which contains the preprocessed version of the headlines.\n",
    "\n",
    "3. **Structured Features:**\n",
    "\n",
    "Finally, we extract relevant features like character count, word count, polarity, and subjectivity from both training and test datasets. This gives us structured features for the model to train on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbf6e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features from Sentiment analysis\n",
    "x_train_snt_obj = X_train['Clean Headline'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_train['Polarity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
    "X_train['Subjectivity'] = [obj.subjectivity for obj in x_train_snt_obj.values]\n",
    "\n",
    "x_test_snt_obj = X_test['Clean Headline'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_test['Polarity'] = [obj.polarity for obj in x_test_snt_obj.values]\n",
    "X_test['Subjectivity'] = [obj.subjectivity for obj in x_test_snt_obj.values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40318bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Clean Headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>supreme court votes 7-2 to legalize all worldl...</td>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>suprem court vote legal worldli vice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hungover man horrified to learn he made dozens...</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>hungov man horrifi learn made dozen plan last ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>emily's list founder: women are the 'problem s...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>emili list founder women problem solver congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>send your kids back to school with confidence</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>send kid back school confid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch: experts talk pesticides and health</td>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>watch expert talk pesticid health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  char_count  word_count  \\\n",
       "0  supreme court votes 7-2 to legalize all worldl...          53           9   \n",
       "1  hungover man horrified to learn he made dozens...          66          12   \n",
       "2  emily's list founder: women are the 'problem s...          65          10   \n",
       "3      send your kids back to school with confidence          45           8   \n",
       "4          watch: experts talk pesticides and health          41           6   \n",
       "\n",
       "   word_density  punctuation_count  title_word_count  upper_case_word_count  \\\n",
       "0      5.300000                  1                 0                      0   \n",
       "1      5.076923                  0                 0                      0   \n",
       "2      5.909091                  4                 0                      0   \n",
       "3      5.000000                  0                 0                      0   \n",
       "4      5.857143                  1                 0                      0   \n",
       "\n",
       "   Polarity  Subjectivity                                     Clean Headline  \n",
       "0       0.2      0.200000               suprem court vote legal worldli vice  \n",
       "1       0.0      0.066667  hungov man horrifi learn made dozen plan last ...  \n",
       "2       0.0      0.000000   emili list founder women problem solver congress  \n",
       "3       0.0      0.000000                        send kid back school confid  \n",
       "4       0.0      0.000000                  watch expert talk pesticid health  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d94505fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>9</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>5.076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>5.909091</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>6</td>\n",
       "      <td>5.857143</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   char_count  word_count  word_density  punctuation_count  title_word_count  \\\n",
       "0          53           9      5.300000                  1                 0   \n",
       "1          66          12      5.076923                  0                 0   \n",
       "2          65          10      5.909091                  4                 0   \n",
       "3          45           8      5.000000                  0                 0   \n",
       "4          41           6      5.857143                  1                 0   \n",
       "\n",
       "   upper_case_word_count  Polarity  Subjectivity  \n",
       "0                      0       0.2      0.200000  \n",
       "1                      0       0.0      0.066667  \n",
       "2                      0       0.0      0.000000  \n",
       "3                      0       0.0      0.000000  \n",
       "4                      0       0.0      0.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting out the structured features from previous experiments\n",
    "X_train_metadata = X_train.drop(['headline', 'Clean Headline'], axis=1).reset_index(drop=True)\n",
    "X_test_metadata = X_test.drop(['headline', 'Clean Headline'], axis=1).reset_index(drop=True)\n",
    "\n",
    "X_train_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34317311",
   "metadata": {},
   "source": [
    "## Model Training: Logistic Regression\n",
    "\n",
    "We now proceed to train a Logistic Regression model on the features extracted from the headlines. Logistic Regression is a binary classification algorithm, and here it will predict whether a given headline is sarcastic or not based on the features created in the previous steps.\n",
    "\n",
    "- C=1: This is the regularization parameter, controlling the trade-off between fitting the training data well and maintaining generalizability. A smaller C increases regularization.\n",
    "- random_state=42: Ensures reproducibility by setting a seed for random number generation.\n",
    "- solver='liblinear': This solver is particularly efficient for small datasets and binary classification.\n",
    "\n",
    "After fitting the model, it will learn the relationships between the features (word counts, polarity, subjectivity, etc.) and whether the headline is sarcastic (is_sarcastic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1a45046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Logistic Regression model\n",
    "lr = LogisticRegression(C=1, random_state=42, solver='liblinear')\n",
    "\n",
    "# Train the model on the training dataset\n",
    "lr.fit(X_train_metadata, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedfd3af",
   "metadata": {},
   "source": [
    "## Prediction and Results\n",
    "\n",
    "After training the Logistic Regression model, the next step is to make predictions on the test dataset and evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce258ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test dataset\n",
    "predictions = lr.predict(X_test_metadata)\n",
    "df_predict=pd.DataFrame(predictions, columns = ['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0d9e9bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction\n",
       "0           0\n",
       "1           1\n",
       "2           1\n",
       "3           0\n",
       "4           1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f18936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11066 entries, 0 to 11065\n",
      "Data columns (total 1 columns):\n",
      " #   Column      Non-Null Count  Dtype\n",
      "---  ------      --------------  -----\n",
      " 0   prediction  11066 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 86.6 KB\n"
     ]
    }
   ],
   "source": [
    "df_predict.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f849be7",
   "metadata": {},
   "source": [
    "**Performance Metrics**\n",
    "To evaluate how well the model is performing, we can use several metrics:\n",
    "\n",
    "- Accuracy: The proportion of correctly classified headlines. It gives a straightforward measure of how often the classifier is correct.\n",
    "- Confusion Matrix: A table that describes the performance of the classification model by showing the counts of true positives, true negatives, false positives, and false negatives. It helps in understanding the types of errors made by the model.\n",
    "- Precision, Recall, and F1-Score: Metrics that provide a deeper insight into the performance, especially if the classes are imbalanced.\n",
    "- Classification Report provides a comprehensive overview of precision, recall, and F1-score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57994348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(Y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "class_report = classification_report(Y_test, predictions)\n",
    "print('Classification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "617dbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict.to_csv('prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5253d8d1",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In this project, we successfully built a logistic regression model to detect sarcasm in news headlines. By utilizing linguistic features and sentiment analysis, the model achieved an accuracy of X% on the test data. The model highlights the importance of sentiment polarity in identifying sarcastic content, but further improvements could be made by incorporating deeper semantic analysis or more advanced algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
